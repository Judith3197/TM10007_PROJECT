{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over all classifiers\n",
    "# Input = X_train_imputed and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "# HOOIi\n",
    "\n",
    "# General packages\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets as ds\n",
    "import seaborn\n",
    "\n",
    "# Classifiers\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn import feature_selection \n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn import decomposition\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.metrics.pairwise import rbf_kernel, sigmoid_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some classifiers\n",
    "svmlin = SVC(kernel='linear', gamma='scale')\n",
    "svmrbf = SVC(kernel='rbf', gamma='scale')\n",
    "svmpoly = SVC(kernel='poly', degree=3, gamma='scale')\n",
    "homemade_random_forest = BaggingClassifier(DecisionTreeClassifier())\n",
    "voting_ensemble = VotingClassifier(\n",
    "    estimators=[('KNN', KNeighborsClassifier()), ('tree', DecisionTreeClassifier()), ('rf', RandomForestClassifier())],\n",
    "    voting='soft')\n",
    "\n",
    "clsfs = [LinearDiscriminantAnalysis(),QuadraticDiscriminantAnalysis(),GaussianNB(), \n",
    "         LogisticRegression(),SGDClassifier(),KNeighborsClassifier(), RandomForestClassifier(), svmlin, svmpoly, svmrbf, homemade_random_forest, voting_ensemble]\n",
    "clsfs_fit = list()\n",
    "\n",
    "# Fit the classifiers\n",
    "for clf in clsfs:\n",
    "    clf.fit(X_train_imputed, y_train)\n",
    "    y_pred = clf.predict(X_train_imputed)\n",
    "    clsfs_fit.append(clf)\n",
    "    # Calculate metrics\n",
    "    if hasattr(clf, 'predict_proba'):\n",
    "    # The first column gives the probability for class = 0, so we take\n",
    "    # the second which gives the probability class = 1:\n",
    "        y_score = clf.predict_proba(X_train_imputed)[:, 1]\n",
    "    else:\n",
    "       y_score = y_pred\n",
    "\n",
    "# The hasattr function checks whether an object, function or package has\n",
    "# a certain attribute. This attribute can be a subfunction, or again an\n",
    "# object or function, but also things like scalars or strings.\n",
    "   \n",
    "    auc=metrics.roc_auc_score(y_train, y_score)\n",
    "    accuracy=metrics.accuracy_score(y_train, y_pred)\n",
    "    F1=metrics.f1_score(y_train,y_pred)\n",
    "    precision=metrics.precision_score(y_train,y_pred)\n",
    "    recall=metrics.recall_score(y_train, y_pred)\n",
    "# accuracy, AUC, f1score, precision, recall\n",
    "    print(type(clf))\n",
    "    print('Acc:' +str(accuracy))\n",
    "    print('AUC:' +str(auc))\n",
    "    print('F1:' +str(F1))\n",
    "    print('precision:' +str(precision))\n",
    "    print('recall:' +str(recall))"
   ]
  }
 ]
}