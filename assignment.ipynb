{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/puckgroen/TM10007_PROJECT/blob/master/assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment template"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CiDn2Sk-VWqE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2407723d-c6dc-45b7-97d5-d9b91f53164e"
      },
      "source": [
        "# Run this to use from colab environment\n",
        "!pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for brats (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55HhaJQKYQTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download the necessary packages\n",
        "import numpy as np\n",
        "\n",
        "# Classifiers\n",
        "from sklearn import model_selection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KVUvqFHNYxH",
        "colab_type": "text"
      },
      "source": [
        "## Data loading and cleaning\n",
        "\n",
        "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-NE_fTbKGe5z",
        "outputId": "cdc1240c-0023-491c-ad23-832f1b922bef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Data loading functions. Uncomment the one you want to use\n",
        "\n",
        "from hn.load_data import load_data\n",
        "\n",
        "data = load_data()\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of features: {len(data.columns)}')\n",
        "print(data.keys())\n",
        "Y = data['label']\n",
        "print(Y)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of samples: 113\n",
            "The number of features: 160\n",
            "Index(['hf_energy', 'hf_entropy', 'hf_kurtosis', 'hf_max', 'hf_mean',\n",
            "       'hf_median', 'hf_min', 'hf_peak', 'hf_quartile_range', 'hf_range',\n",
            "       ...\n",
            "       'tf_LBP_skew_R3_P12', 'tf_LBP_skew_R8_P24', 'tf_LBP_std_R15_P36',\n",
            "       'tf_LBP_std_R3_P12', 'tf_LBP_std_R8_P24', 'tf_NGTDM_Busyness',\n",
            "       'tf_NGTDM_Coarseness', 'tf_NGTDM_Complexity', 'tf_NGTDM_Contrast',\n",
            "       'tf_NGTDM_Strength'],\n",
            "      dtype='object', length=160)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2iAFjW_WR4d",
        "colab_type": "text"
      },
      "source": [
        "The data has 160 features and 113 samples/subjects. The labels are given as either T12 (low) or T34 (high). \n",
        "\n",
        "The aim of this study is to predict the T-stage (high/low) in patients with H&N cancer based on features, extracted from CT. A good performance on this dataset would be above 70% mean accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UqGWjCDWT6R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "ba38ccf1-6ced-4563-801a-ecce139388c7"
      },
      "source": [
        "# Split the dataset in design and test set. Later on the design set should make use of cross-validation? \n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(data, Y, test_size=0.2, stratify=Y)\n",
        "print(len(X_test))\n",
        "print(len(X_train))\n",
        "\n",
        "\n",
        "# Continue with the train dataset and use a 4 fold cross-validation \n",
        "cv_4fold = model_selection.StratifiedKFold(n_splits=4)\n",
        "\n",
        "\n",
        "# Loop over the folds\n",
        "for validation_index, test_index in cv_4fold.split(X_train, y_train):\n",
        "    # For now I had to rearrange the dictionary of X_train to a list, otherwise we cannot index it. \n",
        "    # Not sure if this is the perfect way but just to make it visual, you can see the validation sizes printed. This seems to be ok!\n",
        "    print('Validation size in current fold =')\n",
        "    array = np.array(list(X_train.items()))\n",
        "    \n",
        "    # Split the data properly\n",
        "    X_validation = array[validation_index]\n",
        "    \n",
        "    print(len(X_validation))\n",
        "    y_validation = y_train[validation_index]\n",
        "    \n",
        "    X_test = array[test_index]\n",
        "    y_test = y_train[test_index]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23\n",
            "90\n",
            "Validation size in current fold =\n",
            "67\n",
            "Validation size in current fold =\n",
            "67\n",
            "Validation size in current fold =\n",
            "68\n",
            "Validation size in current fold =\n",
            "68\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}