{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbaseconda3e433ad4382c432eac770014b82f80bd",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import seaborn\n",
    "\n",
    "from hn.load_data import load_data\n",
    "\n",
    "from sklearn import model_selection, metrics, feature_selection, preprocessing, neighbors, decomposition, svm\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.kernel_approximation import RBFSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nieuwe RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "\n",
    "def data_preprocessing(X_train, y_train, X_validation, y_validation):\n",
    "    '''Data preprocessing'''\n",
    "\n",
    "    # 1. Scaling \n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_validation_scaled = scaler.transform(X_validation)\n",
    "\n",
    "    # 2. Feature selection/extraction\n",
    "    # Using the Cumulative Summation of the Explained Variance, we concluded that to  \n",
    "    # retain 95% of the variance we need to use 30 components.\n",
    "    pca = decomposition.PCA(n_components=30)\n",
    "    pca.fit(X_train_scaled)\n",
    "    X_train_pca = pca.transform(X_train_scaled)\n",
    "    X_validation_pca = pca.transform(X_validation_scaled)\n",
    "\n",
    "    return X_train_pca, X_validation_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The number of samples: 113\nThe number of features: 159\nFitting 4 folds for each of 20 candidates, totalling 80 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    6.2s\n[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   13.5s finished\n400\ngini\nFalse\n0.7334558823529412\n0.5217391304347826\n################################################################################\nFitting 4 folds for each of 20 candidates, totalling 80 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:    6.5s\n[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   10.1s finished\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n50\ngini\nFalse\n0.7481617647058824\n0.6521739130434783\n################################################################################\nFitting 4 folds for each of 20 candidates, totalling 80 fits\n[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:    6.4s\n[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    9.9s finished\n400\ngini\nTrue\n0.6911764705882353\n0.7727272727272727\n################################################################################\nFitting 4 folds for each of 20 candidates, totalling 80 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:    6.3s\n[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    9.9s finished\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n50\nentropy\nTrue\n0.75\n0.7272727272727273\n################################################################################\nFitting 4 folds for each of 20 candidates, totalling 80 fits\n[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:    7.6s\n[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   11.4s finished\n200\nentropy\nFalse\n0.7306985294117647\n0.782608695652174\n################################################################################\nFitting 4 folds for each of 20 candidates, totalling 80 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:    8.4s\n[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   13.6s finished\n200\ngini\nTrue\n0.7628676470588235\n0.4782608695652174\n################################################################################\nFitting 4 folds for each of 20 candidates, totalling 80 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:    8.4s\n[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   13.3s finished\n100\nentropy\nTrue\n0.75\n0.6363636363636364\n################################################################################\nFitting 4 folds for each of 20 candidates, totalling 80 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:    8.6s\n[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    8.6s\n[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    8.6s\n[Parallel(n_jobs=-1)]: Done  54 tasks      | elapsed:    8.6s\n[Parallel(n_jobs=-1)]: Done  55 tasks      | elapsed:    8.6s\n[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    8.6s\n[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    8.6s\n[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed:    8.6s\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f2da47a64766>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mgrid_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'n_estimators'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'criterion'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'gini'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'entropy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'bootstrap'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrid_param\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_pca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mbest_hyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Data loading and preprocessing\n",
    "\n",
    "data = load_data()\n",
    "print(f'The number of samples: {len(data.index)}')\n",
    "print(f'The number of features: {len(data.columns)-1}')\n",
    "y_labels = data['label']\n",
    "del data['label']\n",
    "\n",
    "y = sklearn.preprocessing.label_binarize(y_labels, ['T12', 'T34']) # 0 now stands for T12 and 1 for T34\n",
    "y = [i[0] for i in y]\n",
    "y = np.array(y)\n",
    "\n",
    "cv_4fold = model_selection.StratifiedKFold(n_splits=4, shuffle=True)\n",
    "split_X_train, split_X_test, split_y_train, split_y_test = train_test_split(data, y,\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=0.2)\n",
    "\n",
    "# Loop over the folds\n",
    "for _ in range(0,4):\n",
    "    for training_index, validation_index in cv_4fold.split(split_X_train, split_y_train):\n",
    "        train_scores = []\n",
    "        test_scores = []\n",
    "        X_validation = split_X_train.iloc[validation_index]\n",
    "        y_validation = split_y_train[validation_index]\n",
    "        X_train = split_X_train.iloc[training_index]\n",
    "        y_train = split_y_train[training_index]\n",
    "\n",
    "        ## Preprocessing \n",
    "        X_train_pca, X_validation_pca = data_preprocessing(X_train, y_train, X_validation, y_validation)\n",
    "\n",
    "        ## RandomForest Classification\n",
    "        # Stratified K-fold Cross validation\n",
    "        k = 4\n",
    "        skf = StratifiedKFold(k, random_state=0) # cv kan ook op None --> geeft default --> 5-fold cross validation\n",
    "\n",
    "        # Tuning the hyperparameters\n",
    "        grid_param = {'n_estimators': [10, 50, 100, 200, 400],'criterion': ['gini', 'entropy'],'bootstrap': [True, False]}\n",
    "        grid_search = GridSearchCV(RandomForestClassifier(),param_grid=grid_param,cv=skf,n_jobs=-1,verbose=2) \n",
    "        grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "        best_hyperparameters = grid_search.best_params_\n",
    "\n",
    "        # Best hyperparameters\n",
    "        n_estimators = best_hyperparameters.get('n_estimators')\n",
    "        criterion = best_hyperparameters.get('criterion')\n",
    "        bootstrap = best_hyperparameters.get('bootstrap')\n",
    "        print(n_estimators)\n",
    "        print(criterion)\n",
    "        print(bootstrap)\n",
    "        best_result = grid_search.best_score_  \n",
    "        print(best_result)\n",
    "\n",
    "        # Apply classifier with tuned hyperparameters\n",
    "        classifier = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, bootstrap=bootstrap)\n",
    "        classifier.fit(X_train_pca, y_train)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        classifier_predictions_test = classifier.predict(X_validation_pca)\n",
    "        accuracy = metrics.accuracy_score(y_validation, classifier_predictions_test)\n",
    "        print(accuracy)\n",
    "        print('#'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oude RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The number of samples: 113\nThe number of features: 159\n"
    }
   ],
   "source": [
    "# Data\n",
    "from hn.load_data import load_data\n",
    "data = load_data()\n",
    "print(f'The number of samples: {len(data.index)}')\n",
    "print(f'The number of features: {len(data.columns)-1}')\n",
    "y_labels = data['label']\n",
    "del data['label']\n",
    "\n",
    "y = sklearn.preprocessing.label_binarize(y_labels, ['T12', 'T34']) # 0 now stands for T12 and 1 for T34\n",
    "y = [i[0] for i in y]\n",
    "y = np.array(y)\n",
    "\n",
    "cv_4fold = model_selection.StratifiedKFold(n_splits=4, shuffle=True)\n",
    "split_X_train, split_X_test, split_y_train, split_y_test = train_test_split(data, y,\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=0.2)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Loop over the folds\n",
    "for training_index, validation_index in cv_4fold.split(split_X_train, split_y_train):\n",
    "    X_validation = split_X_train.iloc[validation_index]\n",
    "    y_validation = split_y_train[validation_index]\n",
    "    X_train = split_X_train.iloc[training_index]\n",
    "    y_train = split_y_train[training_index]\n",
    "    #print(f'Validation size in current fold = {len(X_validation)}')\n",
    "\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    # scaler = preprocessing.MinMaxScaler()\n",
    "    # scaler = preprocessing.RobustScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_test_scaled = scaler.transform(X_validation)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    #apply preprocessing\n",
    "\n",
    "    n_selected_features = 10\n",
    "    n_samples = len(X_train.index)\n",
    "    n_components = min(n_samples, n_selected_features)\n",
    "    pca = decomposition.PCA(n_components)\n",
    "    pca.fit(X_train_scaled)\n",
    "    X_train_pca = pca.transform(X_train_scaled)\n",
    "    X_validation_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture, we have seen that a random forest has a natural form of feature selection and feature importance. Hence, you may use this feature to find out which features have the most predictive value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opties --> (n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "In opdracht 2.1\n",
    "n_estimators = kan alles zijn\n",
    "bootstrap = True False allebei gebruikt\n",
    "class_weight gevarieerd\n",
    "\n",
    "Lastly, if you have an imbalance in your dataset, or one class is more important than the other, you may want\n",
    "to alter the class weigh in the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified K-fold Cross validation\n",
    "k=4 # K-fold\n",
    "skf = StratifiedKFold(k, random_state=0) \n",
    "# cv kan ook op None --> geeft default --> 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed:    6.8s\n[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   12.3s finished\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n0        0.045576      0.003659         0.003035        0.000581   \n1        0.364433      0.019454         0.033037        0.011247   \n2        0.409993      0.042606         0.073391        0.032532   \n3        1.066013      0.164501         0.063850        0.017354   \n4        1.788096      0.103407         0.092067        0.003814   \n5        0.036658      0.006549         0.002496        0.000074   \n6        0.183432      0.007199         0.011111        0.002742   \n7        0.477816      0.082104         0.043994        0.020770   \n8        0.722489      0.013397         0.042944        0.001808   \n9        1.649211      0.153111         0.114786        0.048117   \n10       0.026604      0.006087         0.003323        0.001207   \n11       0.141045      0.015115         0.011570        0.002370   \n12       0.290257      0.029817         0.024603        0.005101   \n13       0.636113      0.073775         0.051512        0.013829   \n14       1.439686      0.068289         0.105004        0.020416   \n15       0.030668      0.004044         0.003361        0.001148   \n16       0.143039      0.005080         0.014706        0.002452   \n17       0.276965      0.006296         0.025691        0.004179   \n18       0.537278      0.005300         0.043568        0.003237   \n19       1.074315      0.017568         0.081711        0.016315   \n\n   param_bootstrap param_criterion param_n_estimators  \\\n0             True            gini                 10   \n1             True            gini                 50   \n2             True            gini                100   \n3             True            gini                200   \n4             True            gini                400   \n5             True         entropy                 10   \n6             True         entropy                 50   \n7             True         entropy                100   \n8             True         entropy                200   \n9             True         entropy                400   \n10           False            gini                 10   \n11           False            gini                 50   \n12           False            gini                100   \n13           False            gini                200   \n14           False            gini                400   \n15           False         entropy                 10   \n16           False         entropy                 50   \n17           False         entropy                100   \n18           False         entropy                200   \n19           False         entropy                400   \n\n                                               params  split0_test_score  \\\n0   {'bootstrap': True, 'criterion': 'gini', 'n_es...           0.470588   \n1   {'bootstrap': True, 'criterion': 'gini', 'n_es...           0.529412   \n2   {'bootstrap': True, 'criterion': 'gini', 'n_es...           0.529412   \n3   {'bootstrap': True, 'criterion': 'gini', 'n_es...           0.529412   \n4   {'bootstrap': True, 'criterion': 'gini', 'n_es...           0.529412   \n5   {'bootstrap': True, 'criterion': 'entropy', 'n...           0.647059   \n6   {'bootstrap': True, 'criterion': 'entropy', 'n...           0.588235   \n7   {'bootstrap': True, 'criterion': 'entropy', 'n...           0.529412   \n8   {'bootstrap': True, 'criterion': 'entropy', 'n...           0.529412   \n9   {'bootstrap': True, 'criterion': 'entropy', 'n...           0.529412   \n10  {'bootstrap': False, 'criterion': 'gini', 'n_e...           0.588235   \n11  {'bootstrap': False, 'criterion': 'gini', 'n_e...           0.529412   \n12  {'bootstrap': False, 'criterion': 'gini', 'n_e...           0.529412   \n13  {'bootstrap': False, 'criterion': 'gini', 'n_e...           0.529412   \n14  {'bootstrap': False, 'criterion': 'gini', 'n_e...           0.529412   \n15  {'bootstrap': False, 'criterion': 'entropy', '...           0.529412   \n16  {'bootstrap': False, 'criterion': 'entropy', '...           0.470588   \n17  {'bootstrap': False, 'criterion': 'entropy', '...           0.529412   \n18  {'bootstrap': False, 'criterion': 'entropy', '...           0.529412   \n19  {'bootstrap': False, 'criterion': 'entropy', '...           0.470588   \n\n    split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n0            0.588235           0.529412           0.647059         0.558824   \n1            0.647059           0.588235           0.647059         0.602941   \n2            0.764706           0.529412           0.647059         0.617647   \n3            0.764706           0.529412           0.647059         0.617647   \n4            0.882353           0.470588           0.647059         0.632353   \n5            0.588235           0.529412           0.529412         0.573529   \n6            0.588235           0.529412           0.647059         0.588235   \n7            0.764706           0.470588           0.647059         0.602941   \n8            0.823529           0.529412           0.647059         0.632353   \n9            0.882353           0.529412           0.647059         0.647059   \n10           0.647059           0.470588           0.764706         0.617647   \n11           0.764706           0.588235           0.705882         0.647059   \n12           0.647059           0.588235           0.588235         0.588235   \n13           0.823529           0.529412           0.705882         0.647059   \n14           0.823529           0.529412           0.647059         0.632353   \n15           0.647059           0.588235           0.352941         0.529412   \n16           0.823529           0.529412           0.588235         0.602941   \n17           0.705882           0.647059           0.588235         0.617647   \n18           0.647059           0.588235           0.647059         0.602941   \n19           0.705882           0.647059           0.588235         0.602941   \n\n    std_test_score  rank_test_score  \n0         0.065767               19  \n1         0.048774               12  \n2         0.097548                9  \n3         0.097548                9  \n4         0.157703                4  \n5         0.048774               18  \n6         0.041595               16  \n7         0.112958               12  \n8         0.120373                4  \n9         0.144088                3  \n10        0.106046                7  \n11        0.093008                1  \n12        0.041595               16  \n13        0.124784                1  \n14        0.120373                4  \n15        0.110049               20  \n16        0.133977               12  \n17        0.065767                7  \n18        0.048774               12  \n19        0.087001               11  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_bootstrap</th>\n      <th>param_criterion</th>\n      <th>param_n_estimators</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.045576</td>\n      <td>0.003659</td>\n      <td>0.003035</td>\n      <td>0.000581</td>\n      <td>True</td>\n      <td>gini</td>\n      <td>10</td>\n      <td>{'bootstrap': True, 'criterion': 'gini', 'n_es...</td>\n      <td>0.470588</td>\n      <td>0.588235</td>\n      <td>0.529412</td>\n      <td>0.647059</td>\n      <td>0.558824</td>\n      <td>0.065767</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.364433</td>\n      <td>0.019454</td>\n      <td>0.033037</td>\n      <td>0.011247</td>\n      <td>True</td>\n      <td>gini</td>\n      <td>50</td>\n      <td>{'bootstrap': True, 'criterion': 'gini', 'n_es...</td>\n      <td>0.529412</td>\n      <td>0.647059</td>\n      <td>0.588235</td>\n      <td>0.647059</td>\n      <td>0.602941</td>\n      <td>0.048774</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.409993</td>\n      <td>0.042606</td>\n      <td>0.073391</td>\n      <td>0.032532</td>\n      <td>True</td>\n      <td>gini</td>\n      <td>100</td>\n      <td>{'bootstrap': True, 'criterion': 'gini', 'n_es...</td>\n      <td>0.529412</td>\n      <td>0.764706</td>\n      <td>0.529412</td>\n      <td>0.647059</td>\n      <td>0.617647</td>\n      <td>0.097548</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.066013</td>\n      <td>0.164501</td>\n      <td>0.063850</td>\n      <td>0.017354</td>\n      <td>True</td>\n      <td>gini</td>\n      <td>200</td>\n      <td>{'bootstrap': True, 'criterion': 'gini', 'n_es...</td>\n      <td>0.529412</td>\n      <td>0.764706</td>\n      <td>0.529412</td>\n      <td>0.647059</td>\n      <td>0.617647</td>\n      <td>0.097548</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.788096</td>\n      <td>0.103407</td>\n      <td>0.092067</td>\n      <td>0.003814</td>\n      <td>True</td>\n      <td>gini</td>\n      <td>400</td>\n      <td>{'bootstrap': True, 'criterion': 'gini', 'n_es...</td>\n      <td>0.529412</td>\n      <td>0.882353</td>\n      <td>0.470588</td>\n      <td>0.647059</td>\n      <td>0.632353</td>\n      <td>0.157703</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.036658</td>\n      <td>0.006549</td>\n      <td>0.002496</td>\n      <td>0.000074</td>\n      <td>True</td>\n      <td>entropy</td>\n      <td>10</td>\n      <td>{'bootstrap': True, 'criterion': 'entropy', 'n...</td>\n      <td>0.647059</td>\n      <td>0.588235</td>\n      <td>0.529412</td>\n      <td>0.529412</td>\n      <td>0.573529</td>\n      <td>0.048774</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.183432</td>\n      <td>0.007199</td>\n      <td>0.011111</td>\n      <td>0.002742</td>\n      <td>True</td>\n      <td>entropy</td>\n      <td>50</td>\n      <td>{'bootstrap': True, 'criterion': 'entropy', 'n...</td>\n      <td>0.588235</td>\n      <td>0.588235</td>\n      <td>0.529412</td>\n      <td>0.647059</td>\n      <td>0.588235</td>\n      <td>0.041595</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.477816</td>\n      <td>0.082104</td>\n      <td>0.043994</td>\n      <td>0.020770</td>\n      <td>True</td>\n      <td>entropy</td>\n      <td>100</td>\n      <td>{'bootstrap': True, 'criterion': 'entropy', 'n...</td>\n      <td>0.529412</td>\n      <td>0.764706</td>\n      <td>0.470588</td>\n      <td>0.647059</td>\n      <td>0.602941</td>\n      <td>0.112958</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.722489</td>\n      <td>0.013397</td>\n      <td>0.042944</td>\n      <td>0.001808</td>\n      <td>True</td>\n      <td>entropy</td>\n      <td>200</td>\n      <td>{'bootstrap': True, 'criterion': 'entropy', 'n...</td>\n      <td>0.529412</td>\n      <td>0.823529</td>\n      <td>0.529412</td>\n      <td>0.647059</td>\n      <td>0.632353</td>\n      <td>0.120373</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1.649211</td>\n      <td>0.153111</td>\n      <td>0.114786</td>\n      <td>0.048117</td>\n      <td>True</td>\n      <td>entropy</td>\n      <td>400</td>\n      <td>{'bootstrap': True, 'criterion': 'entropy', 'n...</td>\n      <td>0.529412</td>\n      <td>0.882353</td>\n      <td>0.529412</td>\n      <td>0.647059</td>\n      <td>0.647059</td>\n      <td>0.144088</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.026604</td>\n      <td>0.006087</td>\n      <td>0.003323</td>\n      <td>0.001207</td>\n      <td>False</td>\n      <td>gini</td>\n      <td>10</td>\n      <td>{'bootstrap': False, 'criterion': 'gini', 'n_e...</td>\n      <td>0.588235</td>\n      <td>0.647059</td>\n      <td>0.470588</td>\n      <td>0.764706</td>\n      <td>0.617647</td>\n      <td>0.106046</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.141045</td>\n      <td>0.015115</td>\n      <td>0.011570</td>\n      <td>0.002370</td>\n      <td>False</td>\n      <td>gini</td>\n      <td>50</td>\n      <td>{'bootstrap': False, 'criterion': 'gini', 'n_e...</td>\n      <td>0.529412</td>\n      <td>0.764706</td>\n      <td>0.588235</td>\n      <td>0.705882</td>\n      <td>0.647059</td>\n      <td>0.093008</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.290257</td>\n      <td>0.029817</td>\n      <td>0.024603</td>\n      <td>0.005101</td>\n      <td>False</td>\n      <td>gini</td>\n      <td>100</td>\n      <td>{'bootstrap': False, 'criterion': 'gini', 'n_e...</td>\n      <td>0.529412</td>\n      <td>0.647059</td>\n      <td>0.588235</td>\n      <td>0.588235</td>\n      <td>0.588235</td>\n      <td>0.041595</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.636113</td>\n      <td>0.073775</td>\n      <td>0.051512</td>\n      <td>0.013829</td>\n      <td>False</td>\n      <td>gini</td>\n      <td>200</td>\n      <td>{'bootstrap': False, 'criterion': 'gini', 'n_e...</td>\n      <td>0.529412</td>\n      <td>0.823529</td>\n      <td>0.529412</td>\n      <td>0.705882</td>\n      <td>0.647059</td>\n      <td>0.124784</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1.439686</td>\n      <td>0.068289</td>\n      <td>0.105004</td>\n      <td>0.020416</td>\n      <td>False</td>\n      <td>gini</td>\n      <td>400</td>\n      <td>{'bootstrap': False, 'criterion': 'gini', 'n_e...</td>\n      <td>0.529412</td>\n      <td>0.823529</td>\n      <td>0.529412</td>\n      <td>0.647059</td>\n      <td>0.632353</td>\n      <td>0.120373</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.030668</td>\n      <td>0.004044</td>\n      <td>0.003361</td>\n      <td>0.001148</td>\n      <td>False</td>\n      <td>entropy</td>\n      <td>10</td>\n      <td>{'bootstrap': False, 'criterion': 'entropy', '...</td>\n      <td>0.529412</td>\n      <td>0.647059</td>\n      <td>0.588235</td>\n      <td>0.352941</td>\n      <td>0.529412</td>\n      <td>0.110049</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.143039</td>\n      <td>0.005080</td>\n      <td>0.014706</td>\n      <td>0.002452</td>\n      <td>False</td>\n      <td>entropy</td>\n      <td>50</td>\n      <td>{'bootstrap': False, 'criterion': 'entropy', '...</td>\n      <td>0.470588</td>\n      <td>0.823529</td>\n      <td>0.529412</td>\n      <td>0.588235</td>\n      <td>0.602941</td>\n      <td>0.133977</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.276965</td>\n      <td>0.006296</td>\n      <td>0.025691</td>\n      <td>0.004179</td>\n      <td>False</td>\n      <td>entropy</td>\n      <td>100</td>\n      <td>{'bootstrap': False, 'criterion': 'entropy', '...</td>\n      <td>0.529412</td>\n      <td>0.705882</td>\n      <td>0.647059</td>\n      <td>0.588235</td>\n      <td>0.617647</td>\n      <td>0.065767</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.537278</td>\n      <td>0.005300</td>\n      <td>0.043568</td>\n      <td>0.003237</td>\n      <td>False</td>\n      <td>entropy</td>\n      <td>200</td>\n      <td>{'bootstrap': False, 'criterion': 'entropy', '...</td>\n      <td>0.529412</td>\n      <td>0.647059</td>\n      <td>0.588235</td>\n      <td>0.647059</td>\n      <td>0.602941</td>\n      <td>0.048774</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>1.074315</td>\n      <td>0.017568</td>\n      <td>0.081711</td>\n      <td>0.016315</td>\n      <td>False</td>\n      <td>entropy</td>\n      <td>400</td>\n      <td>{'bootstrap': False, 'criterion': 'entropy', '...</td>\n      <td>0.470588</td>\n      <td>0.705882</td>\n      <td>0.647059</td>\n      <td>0.588235</td>\n      <td>0.602941</td>\n      <td>0.087001</td>\n      <td>11</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "# Tuning the hyperparameters\n",
    "grid_param = {'n_estimators': [10, 50, 100, 200, 400],'criterion': ['gini', 'entropy'],'bootstrap': [True, False]}\n",
    "grid_search=GridSearchCV(RandomForestClassifier(),param_grid=grid_param,cv=skf,n_jobs=-1,verbose=2) \n",
    "grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "50\ngini\nFalse\n0.6470588235294118\n"
    }
   ],
   "source": [
    "best_hyperparameters = grid_search.best_params_\n",
    "\n",
    "n_estimators=best_hyperparameters.get('n_estimators')\n",
    "criterion=best_hyperparameters.get('criterion')\n",
    "bootstrap=best_hyperparameters.get('bootstrap')\n",
    "print(n_estimators)\n",
    "print(criterion)\n",
    "print(bootstrap)\n",
    "best_result = grid_search.best_score_  \n",
    "print(best_result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=None, max_features='auto',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=50,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False)"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, bootstrap=bootstrap)\n",
    "classifier.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.6818181818181818\n"
    }
   ],
   "source": [
    "classifier_predictions_test=classifier.predict(X_validation_pca)\n",
    "\n",
    "accuracy=metrics.accuracy_score(y_validation, classifier_predictions_test)\n",
    "print(accuracy)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The number of samples: 113\nThe number of features: 159\nFitting 4 folds for each of 20 candidates, totalling 80 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    6.1s\n[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   12.0s finished\n200\nentropy\nTrue\n0.6709558823529411\n0.6956521739130435\n################################################################################\nFitting 4 folds for each of 20 candidates, totalling 80 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:    6.5s\n[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   10.2s finished\n100\ngini\nFalse\n0.7904411764705883\n0.7391304347826086\n################################################################################\nFitting 4 folds for each of 20 candidates, totalling 80 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:    7.8s\n[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   11.6s finished\n200\nentropy\nFalse\n0.7794117647058822\n0.6363636363636364\n################################################################################\nFitting 4 folds for each of 20 candidates, totalling 80 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:    7.5s\n50\ngini\nTrue\n0.6617647058823529\n0.7727272727272727\n################################################################################\n[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   11.9s finished\n"
    }
   ],
   "source": [
    "# Alles wat hierboven staat in de loop gezet\n",
    "\n",
    "# Data\n",
    "from hn.load_data import load_data\n",
    "data = load_data()\n",
    "print(f'The number of samples: {len(data.index)}')\n",
    "print(f'The number of features: {len(data.columns)-1}')\n",
    "y_labels = data['label']\n",
    "del data['label']\n",
    "\n",
    "y = sklearn.preprocessing.label_binarize(y_labels, ['T12', 'T34']) # 0 now stands for T12 and 1 for T34\n",
    "y = [i[0] for i in y]\n",
    "y = np.array(y)\n",
    "\n",
    "cv_4fold = model_selection.StratifiedKFold(n_splits=4, shuffle=True)\n",
    "split_X_train, split_X_test, split_y_train, split_y_test = train_test_split(data, y,\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=0.2)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Loop over the folds\n",
    "for training_index, validation_index in cv_4fold.split(split_X_train, split_y_train):\n",
    "    X_validation = split_X_train.iloc[validation_index]\n",
    "    y_validation = split_y_train[validation_index]\n",
    "    X_train = split_X_train.iloc[training_index]\n",
    "    y_train = split_y_train[training_index]\n",
    "\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    # scaler = preprocessing.MinMaxScaler()\n",
    "    # scaler = preprocessing.RobustScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_validation_scaled = scaler.transform(X_validation)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "    n_selected_features = 40\n",
    "    n_samples = len(X_train.index)\n",
    "    n_components = min(n_samples, n_selected_features)\n",
    "    pca = decomposition.PCA(n_components)\n",
    "    pca.fit(X_train_scaled)\n",
    "    X_train_pca = pca.transform(X_train_scaled)\n",
    "    X_validation_pca = pca.transform(X_validation_scaled)\n",
    "\n",
    "\n",
    "    # Stratified K-fold Cross validation\n",
    "    k=4\n",
    "    skf = StratifiedKFold(k, random_state=0) \n",
    "    # cv kan ook op None --> geeft default --> 5-fold       cross validation\n",
    "\n",
    "    # Tuning the hyperparameters\n",
    "    grid_param = {'n_estimators': [10, 50, 100, 200, 400],'criterion': ['gini', 'entropy'],'bootstrap': [True, False]}\n",
    "    grid_search=GridSearchCV(RandomForestClassifier(),param_grid=grid_param,cv=skf,n_jobs=-1,verbose=2) \n",
    "    grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "    best_hyperparameters = grid_search.best_params_\n",
    "\n",
    "    # Best hyperparameters\n",
    "    n_estimators=best_hyperparameters.get('n_estimators')\n",
    "    criterion=best_hyperparameters.get('criterion')\n",
    "    bootstrap=best_hyperparameters.get('bootstrap')\n",
    "    print(n_estimators)\n",
    "    print(criterion)\n",
    "    print(bootstrap)\n",
    "    best_result = grid_search.best_score_  \n",
    "    print(best_result)\n",
    "\n",
    "    # Apply classifier with tuned hyperparameters\n",
    "    classifier = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, bootstrap=bootstrap)\n",
    "    classifier.fit(X_train_pca, y_train)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    classifier_predictions_test=classifier.predict(X_validation_pca)\n",
    "\n",
    "    accuracy=metrics.accuracy_score(y_validation, classifier_predictions_test)\n",
    "    print(accuracy)\n",
    "    print('#'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}