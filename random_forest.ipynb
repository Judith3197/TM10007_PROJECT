{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture, we have seen that a random forest has a natural form of feature selection and feature importance. Hence, you may use this feature to find out which features have the most predictive value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opties --> (n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "In opdracht 2.1\n",
    "n_estimators = kan alles zijn\n",
    "bootstrap = True False allebei gebruikt\n",
    "class_weight gevarieerd\n",
    "\n",
    "Lastly, if you have an imbalance in your dataset, or one class is more important than the other, you may want\n",
    "to alter the class weigh in the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning --> BEP Noor, nog meer mogelijkheden (zie hierboven)\n",
    "grid_param = {'n_estimators': [10, 50, 100, 500],'criterion': ['gini', 'entropy'],'bootstrap': [True, False], 'min_samples_leaf': [1, 2, 3, 4, 5],\n",
    "'min_samples_split': [2, 3, 4, 5, 10, 12], 'max_features': [None,'sqrt', 'log2'], 'max_depth':[5, 15, 20, None]}\n",
    "grid_search=GridSearchCV(RandomForestClassifier(),param_grid=grid_param,cv=skf,n_jobs=-1,verbose=2) \n",
    "grid_search.fit(X, y)\n",
    "best_hyperparameters = grid_search.best_params_  \n",
    "\n",
    "n_estimators=best_hyperparameters.get('n_estimators')\n",
    "criterion=best_hyperparameters.get('criterion')\n",
    "bootstrap=best_hyperparameters.get('bootstrap')\n",
    "min_samples_leaf=best_hyperparameters.get('min_samples_leaf')\n",
    "min_samples_split= best_hyperparameters.get('min_samples_split')\n",
    "max_features=best_hyperparameters.get('max_features')\n",
    "max_depth=best_hyperparameters.get('max_depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified K-fold Cross validation\n",
    "k=4 # K-fold\n",
    "skf = StratifiedKFold(k, random_state=0) \n",
    "# cv kan ook op None --> geeft default --> 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning the hyperparameters\n",
    "grid_param = {'n_estimators': [10, 50, 100, 200, 400],'criterion': ['gini', 'entropy'],'bootstrap': [True, False]}\n",
    "grid_search=GridSearchCV(RandomForestClassifier(),param_grid=grid_param,cv=skf,n_jobs=-1,verbose=2) \n",
    "grid_search.fit(X_train_imputed, y_train)\n",
    "best_hyperparameters = grid_search.best_params_\n",
    "\n",
    "n_estimators=best_hyperparameters.get('n_estimators')\n",
    "criterion=best_hyperparameters.get('criterion')\n",
    "bootstrap=best_hyperparameters.get('bootstrap')"
   ]
  }
 ]
}